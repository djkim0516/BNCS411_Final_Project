{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group12_Data_Preprocessing_Fires_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY3q1PASsRKG"
      },
      "source": [
        "## Reverse Geocoder - Modis Datasets\n",
        "\n",
        "This notebook was created in order to translate the lat/long features into state codes that are used on the weather data file. There are around 7 mio usable rows so there is no way to look up the states for each lat/long pair manually. \n",
        "\n",
        "We decided to automate this by using the geocoding API provided by Google. The preocess applied is known as reverse geocoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbhH_Gk273LL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2558239-14aa-4946-bd55-1a5fdaeb2a38"
      },
      "source": [
        "!pip install googlemaps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googlemaps in /usr/local/lib/python3.6/dist-packages (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from googlemaps) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmATTsp8xSvx"
      },
      "source": [
        "We used a shared google drive folder to ease loading the datasets on everyones machines. This notebook cannot be executed in this state without access to said shared folder\n",
        "\n",
        "- We start off with the imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ6tUKoUib6R"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import googlemaps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LUqSYBUWveW"
      },
      "source": [
        "cell to test the google API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl97YPwJ4rNE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "86871825-db50-4885-b787-0f39f85e4bdd"
      },
      "source": [
        "'''\n",
        "gmaps = googlemaps.Client(key='AIzaSyCPBCyv142YkjfcwhqfkXHYrgOLZVHc2go')\n",
        "reverse_geocode_result = gmaps.reverse_geocode((-21.7912, -54.1011))\n",
        "if len(reverse_geocode_result)>=1 and len(reverse_geocode_result[0]['address_components'])>=3:\n",
        "  obj = reverse_geocode_result[0]['address_components'][2]['short_name']\n",
        "  print(obj)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ngmaps = googlemaps.Client(key='AIzaSyCPBCyv142YkjfcwhqfkXHYrgOLZVHc2go')\\nreverse_geocode_result = gmaps.reverse_geocode((-21.7912, -54.1011))\\nif len(reverse_geocode_result)>=1 and len(reverse_geocode_result[0]['address_components'])>=3:\\n  obj = reverse_geocode_result[0]['address_components'][2]['short_name']\\n  print(obj)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntTmwL2GyqIx"
      },
      "source": [
        "- mount drive to access .csv datasets from the shared folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QShHufXv-BdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdc524c-e63e-4d20-f613-d0dff99d6dd5"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WERKPxjNy80i"
      },
      "source": [
        "- we use a list to iteratatively manage the csv files which are named according to their year.\n",
        "- create dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSXpqjIKBkCl"
      },
      "source": [
        "list1=[i for i in range (2000,2020)]\n",
        "list1\n",
        "df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3q4hqIGzSIZ"
      },
      "source": [
        "- iterate over list and append each csv to the dataframe. Edit here to limit the years loaded into the df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XJZ0O6Y3GWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8ea654-c7d8-4820-adcc-eebc3d39b84b"
      },
      "source": [
        "for i in list1:\n",
        "  print(i)\n",
        "  df = df.append(pd.read_csv(f'/content/drive/Shared drives/BNCS411_Final_Project/modis_{i}_Brazil.csv', delimiter=\",\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K-epOtGzc9Z"
      },
      "source": [
        "- we reset the index of the df to eliminate doubles and ease further editing. Column 'index' gets created for some reason.\n",
        "- dropping unused features including 'index' column.\n",
        "- dropping all rows (fires) categorized other than forest fires.\n",
        "- dropping all rows with low confidence ( < 30 ).\n",
        "- sort dataframe by aquisition date and reset the index once more.\n",
        "- finally drop confidence, type & the newly created index column because we already used them to alter/drop rows and don't need the feature anymore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebHMsXmvIAbR"
      },
      "source": [
        "df = df.reset_index()\n",
        "df = df.drop(['index', 'satellite', 'brightness', 'scan', 'track', 'acq_time', 'instrument', 'version', 'bright_t31','frp', 'daynight'], 1)\n",
        "mask = df['type'].isin(['1','2','3'])\n",
        "df.sort_values('type')\n",
        "df = df[~mask]\n",
        "drop_index = df[df['confidence']<=29].index\n",
        "df.drop(drop_index, inplace=True)\n",
        "df = df.sort_values('acq_date')\n",
        "df.reset_index(inplace=True)\n",
        "df = df.drop(['confidence', 'index', 'type'], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSCXpXOW01K2"
      },
      "source": [
        "- Create statecode column\n",
        "- randomize df to extract 50 000 values later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP-s3Lwz3vVy"
      },
      "source": [
        "df[\"statecode\"] = \"\"\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU2o1TQWUBpF"
      },
      "source": [
        "- Create smaller df2 from randomized df\n",
        "- iterate over the reduced df2 and get statecodes for all Lat/Long pairs\n",
        "- skip on corrupted lat/long values\n",
        "- Execute only once(!) and write onto csv file to save for future use\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B59mV2GMHiuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5a5cc1cf-0422-4d85-96d6-a46a3073965b"
      },
      "source": [
        "'''\n",
        "df2 = df.head(50000)\n",
        "for i in df2.index:\n",
        "  rg_result = gmaps.reverse_geocode((df2.loc[i, 'latitude'], df2.loc[i, 'longitude']))\n",
        "  if len(rg_result)>=1 and len(rg_result[0]['address_components'])>=3:\n",
        "    df2.at[i,'statecode'] = rg_result[0]['address_components'][2]['short_name']\n",
        "    print(i)\n",
        "  else:\n",
        "    print('skip')\n",
        "\n",
        "df2.to_csv('rand_fires.csv')\n",
        "!cp rand_fires.csv \"/content/drive/Shared drives/BNCS411_Final_Project\"\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndf2 = df.head(50000)\\nfor i in df2.index:\\n  rg_result = gmaps.reverse_geocode((df2.loc[i, \\'latitude\\'], df2.loc[i, \\'longitude\\']))\\n  if len(rg_result)>=1 and len(rg_result[0][\\'address_components\\'])>=3:\\n    df2.at[i,\\'statecode\\'] = rg_result[0][\\'address_components\\'][2][\\'short_name\\']\\n    print(i)\\n  else:\\n    print(\\'skip\\')\\n\\ndf2.to_csv(\\'rand_fires.csv\\')\\n!cp rand_fires.csv \"/content/drive/Shared drives/BNCS411_Final_Project\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10fKhRqyX3S0"
      },
      "source": [
        "As we executed the cell above this one only once, we can now reload the csv file that was written earlier into df2 and continue using it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei38X9nCYSG1"
      },
      "source": [
        "df2 = pd.DataFrame()\n",
        "df2 = df2.append(pd.read_csv(f'/content/drive/Shared drives/BNCS411_Final_Project/rand_fires.csv', delimiter=\",\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzNb9TxYcVTW"
      },
      "source": [
        "Here we clean up our df2 to make it useable afterwards\n",
        "- save length of statecode values into 'length'\n",
        "- delete all rows where length is > 2. Those are all faulty API requests\n",
        "- drop accidentally created column 'Unnamed: 0'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3brHRdm_GN9S"
      },
      "source": [
        "df2['length'] = df2.statecode.str.len() \n",
        "pd.set_option('display.max_rows', None)\n",
        "df2 = df2[df2.length < 3]\n",
        "del df2['length']\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "del df2['Unnamed: 0']\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbwF_yqAWKNt"
      },
      "source": [
        "scatterplot of reduced df2 (50 000 rows)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbZUfwEhJdzx"
      },
      "source": [
        "df2.to_csv('rand_fires.csv')\n",
        "!cp rand_fires.csv \"/content/drive/Shared drives/BNCS411_Final_Project\"\n",
        "df.to_csv('rand_fires_empty.csv')\n",
        "!cp rand_fires_empty.csv \"/content/drive/Shared drives/BNCS411_Final_Project\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urei3LVPXbro"
      },
      "source": [
        "TODO:\n",
        "- ~~create column 'Statecode'~~\n",
        "- ~~**NEW** reduce size of df to managable requests~~\n",
        "- ~~iterate over each line: make api request & save into 'Statecode'~~ **big problem here. Too many requests.**\n",
        "- ~~**NEW** Use the data from the reduced dataframe (df2) to predict the rest of the df. Possible SVM use?~~\n",
        "- ~~drop 'latitude' & 'longitude'~~\n",
        "- ~~sort by aqu_date -> statecode~~\n",
        "- ~~create df3 for the final data structure (state, date, fires)~~\n",
        "- ~~count occurances per day/state & save into column~~\n"
      ]
    }
  ]
}