{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group12_Entire_Brazil_by_Month.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7LVpubMUwvF"
      },
      "source": [
        "##Brazil fire data by month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy4s3buaxXGE"
      },
      "source": [
        "### Bi-Weekly Report ###\n",
        "**What we did:**\n",
        "\n",
        "Finalized preprocessing & merged our data together into one .csv file ('weather_with_fires.csv')\n",
        "\n",
        "**What we are doing in this notebook:**\n",
        "\n",
        "We created a daily scale for month-specific fire danger to use as classifier in our predicition. It is separated into 4 tiers.\n",
        "\n",
        "\n",
        "**What we will do:**\n",
        "\n",
        "With the preprocessed data, we will apply SVM method to classify whether given data predicts 4 different classes we divided. Also, we will compare SVM to different methods to see if SVM yields highest accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTWtt2FSUXDl",
        "outputId": "6b51f21c-ea8f-4069-9db0-ee675dd0b7f7"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj6h7ggc3-_a"
      },
      "source": [
        "- load the .csv file we created in Data_Preprocessing_Weather_2.ipynb\n",
        "- drop 'Unnamed' column & create 'Scale' column. Scale determines the fire-danger of a state on a certain day.\n",
        "- translate Date to datetime to make date-specific calculations easier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULg3-fVCV7fa"
      },
      "source": [
        "data = pd.read_csv('/content/drive/Shareddrives/BNCS411_Final_Project/weather_with_fires.csv')\n",
        "data = data.drop(columns=['Unnamed: 0'])\n",
        "data = data.append(pd.DataFrame(columns=['Scale']))\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "mask = (data['Date'] >= '2000-11-01') & (data['Date'] <= '2018-12-31')\n",
        "data_train = data.loc[mask]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdW8qehOS8JJ"
      },
      "source": [
        "data_train.State.unique()\n",
        "statelist = ['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG','MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RR', 'RS','SC', 'SE', 'SP', 'TO']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDERoR065VeJ"
      },
      "source": [
        "As each month varies alot in fire danger, the scale has to vary too. We chose a scale from 1 - 4 with:\n",
        "1. being the the first 25% of days which are mostly 0 fire days.\n",
        "2. includes the values for 50% of the data between the 25% & the 75% quantile. \n",
        "3. is determined by the next 10% of days so the upper and lower border of 75%-85%.\n",
        "4. is used for all days more than that.\n",
        "\n",
        "We iterate over each month & apply the scale for that month onto each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW5UJBLNX0-x",
        "outputId": "2946d7ad-ccf0-4e93-e510-73a457743d63"
      },
      "source": [
        "for h in statelist:\n",
        "  stat = data.loc[data['State'] == h]\n",
        "  for j in range(1,13):\n",
        "      mon_mask = stat['Date'].map(lambda x: x.month) == j\n",
        "      mon = stat[mon_mask]\n",
        "      temp = np.array(mon.quantile([.25, .75, .85]))[:,0]\n",
        "      print(temp)\n",
        "      for i in mon.index:\n",
        "          if data.loc[i, 'Fires'] <= temp[0]:\n",
        "              data.loc[i, 'Scale'] = 1\n",
        "          elif temp[0] < data.loc[i, 'Fires'] <= temp[1]:\n",
        "              data.loc[i, 'Scale'] = 2\n",
        "          elif temp[0] < data.loc[i, 'Fires'] <= temp[2]:\n",
        "              data.loc[i, 'Scale'] = 3\n",
        "          else:\n",
        "              data.loc[i, 'Scale'] = 4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 1.]\n",
            "[0.   1.   2.65]\n",
            "[ 0. 10. 19.]\n",
            "[  7.  83. 152.]\n",
            "[ 13.   178.   295.25]\n",
            "[ 0.  20.  42.8]\n",
            "[0. 1. 2.]\n",
            "[0. 0. 0.]\n",
            "[ 0. 13. 19.]\n",
            "[ 0.  9. 14.]\n",
            "[0. 5. 7.]\n",
            "[0. 1. 2.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 2. 4.]\n",
            "[ 0.   7.  10.8]\n",
            "[ 1. 12. 17.]\n",
            "[ 1. 13. 19.]\n",
            "[0. 3. 6.]\n",
            "[0. 2. 4.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 1.]\n",
            "[0. 1. 1.]\n",
            "[0.   3.75 5.65]\n",
            "[ 3. 29. 50.]\n",
            "[ 43.  213.  284.6]\n",
            "[ 39.  177.  264.6]\n",
            "[  9.   77.  121.8]\n",
            "[ 1.  25.  43.3]\n",
            "[ 0.  7. 12.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 1. 2.]\n",
            "[ 1. 10. 14.]\n",
            "[ 4.   35.25 50.55]\n",
            "[ 4.  57.5 88. ]\n",
            "[ 0. 17. 35.]\n",
            "[ 2. 18. 26.]\n",
            "[ 2.   16.   25.75]\n",
            "[ 2. 18. 26.]\n",
            "[ 2. 14. 19.]\n",
            "[ 4.  17.  22.8]\n",
            "[ 6. 25. 31.]\n",
            "[11.  34.  45.8]\n",
            "[ 23.   83.  118.8]\n",
            "[ 71.   305.75 419.  ]\n",
            "[ 47.  268.  377.6]\n",
            "[ 3.   50.   90.15]\n",
            "[ 1. 25. 39.]\n",
            "[ 0.   9.  17.8]\n",
            "[0. 1. 2.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 1.]\n",
            "[0. 1. 2.]\n",
            "[0. 2. 4.]\n",
            "[ 0.   7.  11.8]\n",
            "[ 2.   16.   22.65]\n",
            "[ 5. 46. 68.]\n",
            "[  6.   90.  137.3]\n",
            "[  4.    72.25 112.3 ]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 1.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 1. 2.]\n",
            "[0. 2. 3.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 2. 3.]\n",
            "[0.   2.   3.95]\n",
            "[0. 4. 6.]\n",
            "[0. 5. 8.]\n",
            "[0. 5. 8.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 1.]\n",
            "[0. 3. 6.]\n",
            "[0. 3. 6.]\n",
            "[0. 4. 7.]\n",
            "[ 0.  7. 10.]\n",
            "[ 3. 15. 20.]\n",
            "[ 9. 26. 35.]\n",
            "[21. 50. 65.]\n",
            "[ 38.  112.  144.8]\n",
            "[ 63.   246.75 325.3 ]\n",
            "[ 14.  116.  183.6]\n",
            "[ 0. 11. 20.]\n",
            "[0. 3. 8.]\n",
            "[ 0.  14.  29.8]\n",
            "[0. 2. 5.]\n",
            "[0. 2. 4.]\n",
            "[0. 4. 7.]\n",
            "[ 1. 13. 18.]\n",
            "[12.   54.   71.65]\n",
            "[ 32. 122. 158.]\n",
            "[ 58.  237.  352.8]\n",
            "[ 80.75 414.   557.25]\n",
            "[ 52.  336.  517.4]\n",
            "[ 32.75 273.5  417.  ]\n",
            "[ 10.   156.25 248.15]\n",
            "[ 0.  7. 12.]\n",
            "[ 1.  9. 13.]\n",
            "[ 1.  9. 13.]\n",
            "[ 2.   10.75 14.  ]\n",
            "[ 3. 15. 20.]\n",
            "[ 7. 23. 29.]\n",
            "[17. 51. 68.]\n",
            "[ 39.  109.  160.6]\n",
            "[ 70.25 236.   330.65]\n",
            "[ 22.  217.  323.6]\n",
            "[ 1. 22. 44.]\n",
            "[ 0.  8. 14.]\n",
            "[ 0. 13. 19.]\n",
            "[ 1.   14.   21.75]\n",
            "[ 1. 13. 18.]\n",
            "[ 1. 13. 18.]\n",
            "[ 1. 13. 21.]\n",
            "[ 2. 20. 31.]\n",
            "[ 9.  40.  54.8]\n",
            "[ 22.  108.  160.6]\n",
            "[ 25.25 156.75 222.65]\n",
            "[ 7. 66. 94.]\n",
            "[ 1. 32. 50.]\n",
            "[ 1.   17.   28.15]\n",
            "[ 2.  26.  42.6]\n",
            "[ 1. 20. 36.]\n",
            "[ 3. 33. 53.]\n",
            "[ 9.25 54.   80.  ]\n",
            "[ 27.  109.  137.8]\n",
            "[ 67.25 187.5  247.  ]\n",
            "[ 88.  275.  422.2]\n",
            "[ 202.  773. 1063.]\n",
            "[ 312.25 1322.75 1802.95]\n",
            "[ 73.  425.  643.2]\n",
            "[ 12.    97.   150.15]\n",
            "[ 2.   43.   71.15]\n",
            "[ 0. 27. 49.]\n",
            "[0.   3.   5.75]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 3.]\n",
            "[0. 5. 8.]\n",
            "[ 3.   23.   33.65]\n",
            "[ 19.   99.  158.8]\n",
            "[ 149.   703.  1152.4]\n",
            "[137.25 664.5  952.95]\n",
            "[ 87.  472.  676.2]\n",
            "[ 73.75 567.   806.  ]\n",
            "[ 17.   215.25 373.  ]\n",
            "[0. 5. 7.]\n",
            "[0. 1. 2.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 1.]\n",
            "[0. 2. 3.]\n",
            "[0. 4. 6.]\n",
            "[ 1.  10.  16.8]\n",
            "[ 2. 18. 26.]\n",
            "[ 1. 12. 18.]\n",
            "[ 0.  9. 13.]\n",
            "[0. 3. 6.]\n",
            "[0. 2. 3.]\n",
            "[0. 1. 1.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 1.]\n",
            "[0. 2. 3.]\n",
            "[ 1. 10. 15.]\n",
            "[ 4. 24. 34.]\n",
            "[ 4. 26. 35.]\n",
            "[ 1. 17. 26.]\n",
            "[0. 6. 9.]\n",
            "[0. 2. 4.]\n",
            "[0. 2. 4.]\n",
            "[0. 3. 5.]\n",
            "[ 1.  9. 13.]\n",
            "[ 4. 26. 38.]\n",
            "[13.  57.  83.8]\n",
            "[ 31. 128. 188.]\n",
            "[ 61.5  248.75 343.  ]\n",
            "[ 31.  190.  269.8]\n",
            "[ 11.    82.75 122.  ]\n",
            "[ 2.   33.   51.15]\n",
            "[0. 3. 5.]\n",
            "[0. 3. 6.]\n",
            "[0. 5. 8.]\n",
            "[ 0.   10.   13.55]\n",
            "[ 0. 11. 15.]\n",
            "[ 1. 15. 22.]\n",
            "[ 2. 23. 37.]\n",
            "[ 7.   58.75 89.05]\n",
            "[ 4.   50.75 85.  ]\n",
            "[ 1. 14. 28.]\n",
            "[ 0.   10.   18.35]\n",
            "[ 0.  5. 10.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 3.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 3. 4.]\n",
            "[0. 6. 9.]\n",
            "[ 1. 12. 18.]\n",
            "[ 0. 14. 25.]\n",
            "[ 0.  6. 11.]\n",
            "[0. 1. 2.]\n",
            "[0. 0. 1.]\n",
            "[0. 4. 6.]\n",
            "[0. 1. 3.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 1.]\n",
            "[0. 0. 1.]\n",
            "[0. 1. 2.]\n",
            "[0. 3. 4.]\n",
            "[0. 5. 6.]\n",
            "[ 1.  8. 11.]\n",
            "[ 1. 11. 16.]\n",
            "[ 0.    9.   15.15]\n",
            "[ 1. 26. 45.]\n",
            "[ 2.   31.   55.75]\n",
            "[ 2.  43.  79.8]\n",
            "[ 0. 11. 24.]\n",
            "[0. 1. 2.]\n",
            "[0.   0.   0.65]\n",
            "[0. 0. 0.]\n",
            "[0. 1. 2.]\n",
            "[0. 3. 5.]\n",
            "[ 0.  9. 15.]\n",
            "[ 0.   10.25 18.  ]\n",
            "[ 0.   14.   23.15]\n",
            "[0. 4. 6.]\n",
            "[0. 3. 5.]\n",
            "[0. 5. 8.]\n",
            "[ 0.    6.75 10.  ]\n",
            "[0. 5. 7.]\n",
            "[0.   4.   7.65]\n",
            "[ 0. 13. 25.]\n",
            "[ 1. 43. 73.]\n",
            "[ 0.   21.   36.65]\n",
            "[ 0.  7. 13.]\n",
            "[0. 5. 9.]\n",
            "[0. 4. 7.]\n",
            "[0.   2.   3.85]\n",
            "[0. 2. 3.]\n",
            "[0. 2. 4.]\n",
            "[0. 3. 6.]\n",
            "[0. 3. 6.]\n",
            "[0. 3. 8.]\n",
            "[ 0.    9.75 18.  ]\n",
            "[ 0.   43.75 74.05]\n",
            "[ 0. 22. 42.]\n",
            "[ 0.  4. 11.]\n",
            "[0.   4.   8.35]\n",
            "[0. 2. 5.]\n",
            "[0. 3. 5.]\n",
            "[0. 3. 5.]\n",
            "[0. 2. 4.]\n",
            "[0. 1. 2.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 1.]\n",
            "[0. 2. 3.]\n",
            "[0. 3. 5.]\n",
            "[0. 5. 8.]\n",
            "[ 0. 11. 16.]\n",
            "[ 1. 12. 18.]\n",
            "[ 3. 22. 29.]\n",
            "[ 4. 29. 43.]\n",
            "[ 7.   38.75 54.  ]\n",
            "[16.  62.  81.8]\n",
            "[ 28.   94.  124.8]\n",
            "[ 16.  105.5 139. ]\n",
            "[ 4.  48.  72.8]\n",
            "[ 1. 20. 32.]\n",
            "[ 0.  8. 13.]\n",
            "[0. 4. 6.]\n",
            "[0.   2.   4.75]\n",
            "[0. 3. 5.]\n",
            "[ 0.  9. 15.]\n",
            "[ 5. 33. 46.]\n",
            "[19.   76.75 95.65]\n",
            "[ 42. 116. 141.]\n",
            "[ 79.  224.  302.6]\n",
            "[116.   448.   628.15]\n",
            "[ 17. 197. 299.]\n",
            "[ 0. 21. 36.]\n",
            "[ 0.    6.   11.15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4oEcREYqT8_"
      },
      "source": [
        "def get_state_nr (row, Statelist):\n",
        "  for i in Statelist:\n",
        "    if row['State'] == i:\n",
        "      return Statelist.index(i) + 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8dh26l8dFTF"
      },
      "source": [
        "data['Scale']=data['Scale'].astype('int')\n",
        "data['Month'] = data['Date'].map(lambda x: x.month)\n",
        "data['StateNr'] = data.apply(lambda row: get_state_nr(row, statelist), axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kej8xX3jWyX8"
      },
      "source": [
        "data['FirPrev'] = 0\n",
        "data_temp = data.sort_values([\"StateNr\", \"Date\"])\n",
        "data_temp\n",
        "\n",
        "for k in data_temp['StateNr'].unique():\n",
        "    temp = data_temp[data_temp['StateNr']==k]\n",
        "    for i in range(1, len(temp)):\n",
        "        data.loc[temp.index[i], 'FirPrev'] = data.loc[temp.index[i-1], 'Fires']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j17KHmdeSVUV"
      },
      "source": [
        "mask = (data['Date'] >= '2000-11-01') & (data['Date'] <= '2018-12-31')\r\n",
        "data_train = data.loc[mask]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0GAF5Ul9nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60dfc2f-2872-460f-8a36-2effbebfa792"
      },
      "source": [
        "knc = KNeighborsClassifier()\n",
        "#cross_validate(knc, X_train, y_train, cv=5, n_jobs=-1,verbose=1)\n",
        "X = data_train[['MaxTemp','MinTemp','RelHum', 'WindVel', 'Month', 'StateNr']]\n",
        "y = data_train['Scale']\n",
        "for train_index, test_index in KFold(n_splits=10, random_state=42, shuffle=True).split(X, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "    y_train = pd.get_dummies(y_train)\n",
        "    y_test = pd.get_dummies(y_test)\n",
        "    knc.fit(X_train,y_train)\n",
        "    print(knc.score(X_test, y_test))\n",
        "\n",
        "pickle.dump(knc, open( \"/content/drive/Shareddrives/BNCS411_Final_Project/Group12_knc.pkl\", \"wb\" ))\n",
        "\n",
        "\n",
        "#knc.fit(X_train, y_train)\n",
        "#accuracy = knc.score(X_test, y_test) \n",
        "#print(accuracy)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    11     12     22 ... 171867 171878 171879]\n",
            "0.45296410495084066\n",
            "TRAIN: [     1      2      3 ... 171884 171885 171886] TEST: [     0     20     24 ... 171849 171872 171874]\n",
            "0.4504043283495259\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     4     23     39 ... 171856 171861 171881]\n",
            "0.447960905230089\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    31     48     57 ... 171863 171876 171880]\n",
            "0.45063703531328175\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     3     38     41 ... 171869 171875 171883]\n",
            "0.4503461516085869\n",
            "TRAIN: [     0      1      2 ... 171882 171883 171884] TEST: [     8     14     17 ... 171873 171885 171886]\n",
            "0.44790272848915\n",
            "TRAIN: [     0      2      3 ... 171883 171885 171886] TEST: [     1      6      7 ... 171841 171857 171884]\n",
            "0.450113444644831\n",
            "TRAIN: [     0      1      3 ... 171884 171885 171886] TEST: [     2      9     13 ... 171859 171864 171865]\n",
            "0.4497323714219223\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    10     16     18 ... 171862 171877 171882]\n",
            "0.44711426576681407\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     5     15     26 ... 171847 171860 171868]\n",
            "0.4492669304165697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0207f94D8rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357cb32f-a509-457e-e18b-f9e4c5c45763"
      },
      "source": [
        "dtc = DecisionTreeClassifier()\n",
        "X = data_train[['MaxTemp','MinTemp','RelHum', 'WindVel', 'Month', 'StateNr']]\n",
        "y = data_train['Scale']\n",
        "for train_index, test_index in KFold(n_splits=10, random_state=42, shuffle=True, ).split(X, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "    y_train = pd.get_dummies(y_train)\n",
        "    y_test = pd.get_dummies(y_test)\n",
        "    dtc.fit(X_train,y_train)\n",
        "    print(dtc.score(X_test, y_test))\n",
        "\n",
        "pickle.dump(dtc, open( \"/content/drive/Shareddrives/BNCS411_Final_Project/Group12_dtc.pkl\", \"wb\" ))\n",
        "\n",
        "#dtc = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "#dtc.score(X_test, y_test)\n",
        "#dtc.feature_importances_"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    11     12     22 ... 171867 171878 171879]\n",
            "0.46355227180173364\n",
            "TRAIN: [     1      2      3 ... 171884 171885 171886] TEST: [     0     20     24 ... 171849 171872 171874]\n",
            "0.46634475536680436\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     4     23     39 ... 171856 171861 171881]\n",
            "0.4595962534178835\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    31     48     57 ... 171863 171876 171880]\n",
            "0.4654139275117808\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     3     38     41 ... 171869 171875 171883]\n",
            "0.46721740648088894\n",
            "TRAIN: [     0      1      2 ... 171882 171883 171884] TEST: [     8     14     17 ... 171873 171885 171886]\n",
            "0.46081796497760197\n",
            "TRAIN: [     0      2      3 ... 171883 171885 171886] TEST: [     1      6      7 ... 171841 171857 171884]\n",
            "0.4632032113560998\n",
            "TRAIN: [     0      1      3 ... 171884 171885 171886] TEST: [     2      9     13 ... 171859 171864 171865]\n",
            "0.4628228996974633\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    10     16     18 ... 171862 171877 171882]\n",
            "0.4595648126599953\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     5     15     26 ... 171847 171860 171868]\n",
            "0.46526646497556434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP5FeM9keI7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb86e9e-081b-4305-e618-33fbc2390f68"
      },
      "source": [
        "rfc = RandomForestClassifier(max_depth=15, random_state=42)\n",
        "X = data_train[['MaxTemp','MinTemp','RelHum', 'WindVel', 'Month', 'StateNr']]\n",
        "y = data_train['Scale']\n",
        "for train_index, test_index in KFold(n_splits=10, random_state=42, shuffle=True).split(X, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "    y_train = pd.get_dummies(y_train)\n",
        "    y_test = pd.get_dummies(y_test)\n",
        "    rfc.fit(X_train,y_train)\n",
        "    print(rfc.score(X_test, y_test))\n",
        "\n",
        "pickle.dump(rfc, open( \"/content/drive/Shareddrives/BNCS411_Final_Project/Group12_rfc.pkl\", \"wb\" ))\n",
        "\n",
        "#clf.fit(X_train, y_train)\n",
        "#y_pred = clf.predict(X_test)\n",
        "\n",
        "#print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    11     12     22 ... 171867 171878 171879]\n",
            "0.3915294665192856\n",
            "TRAIN: [     1      2      3 ... 171884 171885 171886] TEST: [     0     20     24 ... 171849 171872 171874]\n",
            "0.39222758741055325\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     4     23     39 ... 171856 171861 171881]\n",
            "0.38693350398510673\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    31     48     57 ... 171863 171876 171880]\n",
            "0.39123858281459073\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     3     38     41 ... 171869 171875 171883]\n",
            "0.3947291872709291\n",
            "TRAIN: [     0      1      2 ... 171882 171883 171884] TEST: [     8     14     17 ... 171873 171885 171886]\n",
            "0.38675897376228985\n",
            "TRAIN: [     0      2      3 ... 171883 171885 171886] TEST: [     1      6      7 ... 171841 171857 171884]\n",
            "0.3834428995287684\n",
            "TRAIN: [     0      1      3 ... 171884 171885 171886] TEST: [     2      9     13 ... 171859 171864 171865]\n",
            "0.3907959041191529\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [    10     16     18 ... 171862 171877 171882]\n",
            "0.39114498487316735\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     5     15     26 ... 171847 171860 171868]\n",
            "0.3868978356993251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccgKGCA3HbOW"
      },
      "source": [
        "def ANN1():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_shape=(6,), activation='tanh'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(tf.nn.tanh))\n",
        "    model.add(Dense(256, activation='tanh'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(tf.nn.tanh))\n",
        "    model.add(Dense(512,  activation='tanh'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(tf.nn.tanh))\n",
        "    model.add(Dense(128, activation='sigmoid'))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PMeco31Iiqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28e5937-ddc1-4858-b3dd-feedb076dee0"
      },
      "source": [
        "Mymodel = ANN1()\n",
        "history = {'accuracy': [], 'loss': [], 'val_accuracy': [], 'val_loss': []}\n",
        "X = data_train[['MaxTemp','MinTemp','RelHum', 'WindVel', 'Month', 'StateNr']]\n",
        "y = data_train['Scale']\n",
        "for train_index, test_index in KFold(n_splits=5, random_state=42, shuffle=True).split(X, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "    y_train = pd.get_dummies(y_train)\n",
        "    y_test = pd.get_dummies(y_test)\n",
        "    temp = Mymodel.fit(X_train,y_train, batch_size = 128, epochs=30, validation_data=(X_test, y_test))\n",
        "    for key, values in temp.history.items():\n",
        "        history[key].extend(values)\n",
        "\n",
        "Mymodel.save('/content/drive/Shareddrives/BNCS411_Final_Project/Group12_ANN.h5')\n",
        "pd.DataFrame(history).to_csv('/content/drive/Shareddrives/BNCS411_Final_Project/Group12_ANN_history.csv')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [     1      2      3 ... 171884 171885 171886] TEST: [     0     11     12 ... 171874 171878 171879]\n",
            "Epoch 1/30\n",
            "1075/1075 [==============================] - 18s 17ms/step - loss: 1.0983 - accuracy: 0.5363 - val_loss: 1.0864 - val_accuracy: 0.5474\n",
            "Epoch 2/30\n",
            "1075/1075 [==============================] - 17s 16ms/step - loss: 1.0678 - accuracy: 0.5519 - val_loss: 1.0809 - val_accuracy: 0.5514\n",
            "Epoch 3/30\n",
            "1075/1075 [==============================] - 19s 18ms/step - loss: 1.0575 - accuracy: 0.5567 - val_loss: 1.0718 - val_accuracy: 0.5461\n",
            "Epoch 4/30\n",
            "1075/1075 [==============================] - 17s 15ms/step - loss: 1.0487 - accuracy: 0.5604 - val_loss: 1.0649 - val_accuracy: 0.5531\n",
            "Epoch 5/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0426 - accuracy: 0.5629 - val_loss: 1.0607 - val_accuracy: 0.5604\n",
            "Epoch 6/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0373 - accuracy: 0.5658 - val_loss: 1.0335 - val_accuracy: 0.5672\n",
            "Epoch 7/30\n",
            "1075/1075 [==============================] - 15s 14ms/step - loss: 1.0352 - accuracy: 0.5670 - val_loss: 1.0442 - val_accuracy: 0.5649\n",
            "Epoch 8/30\n",
            "1075/1075 [==============================] - 17s 16ms/step - loss: 1.0324 - accuracy: 0.5676 - val_loss: 1.0798 - val_accuracy: 0.5527\n",
            "Epoch 9/30\n",
            "1075/1075 [==============================] - 20s 18ms/step - loss: 1.0293 - accuracy: 0.5686 - val_loss: 1.0430 - val_accuracy: 0.5703\n",
            "Epoch 10/30\n",
            "1075/1075 [==============================] - 20s 18ms/step - loss: 1.0269 - accuracy: 0.5698 - val_loss: 1.0525 - val_accuracy: 0.5493\n",
            "Epoch 11/30\n",
            "1075/1075 [==============================] - 18s 17ms/step - loss: 1.0259 - accuracy: 0.5703 - val_loss: 1.0603 - val_accuracy: 0.5559\n",
            "Epoch 12/30\n",
            "1075/1075 [==============================] - 19s 18ms/step - loss: 1.0246 - accuracy: 0.5715 - val_loss: 1.0273 - val_accuracy: 0.5713\n",
            "Epoch 13/30\n",
            "1075/1075 [==============================] - 20s 18ms/step - loss: 1.0231 - accuracy: 0.5722 - val_loss: 1.0704 - val_accuracy: 0.5536\n",
            "Epoch 14/30\n",
            "1075/1075 [==============================] - 19s 17ms/step - loss: 1.0217 - accuracy: 0.5730 - val_loss: 1.0239 - val_accuracy: 0.5745\n",
            "Epoch 15/30\n",
            "1075/1075 [==============================] - 20s 19ms/step - loss: 1.0203 - accuracy: 0.5732 - val_loss: 1.0217 - val_accuracy: 0.5786\n",
            "Epoch 16/30\n",
            "1075/1075 [==============================] - 19s 18ms/step - loss: 1.0188 - accuracy: 0.5735 - val_loss: 1.0412 - val_accuracy: 0.5647\n",
            "Epoch 17/30\n",
            "1075/1075 [==============================] - 17s 16ms/step - loss: 1.0192 - accuracy: 0.5740 - val_loss: 1.0284 - val_accuracy: 0.5710\n",
            "Epoch 18/30\n",
            "1075/1075 [==============================] - 17s 16ms/step - loss: 1.0178 - accuracy: 0.5745 - val_loss: 1.0184 - val_accuracy: 0.5729\n",
            "Epoch 19/30\n",
            "1075/1075 [==============================] - 19s 18ms/step - loss: 1.0165 - accuracy: 0.5754 - val_loss: 1.0589 - val_accuracy: 0.5463\n",
            "Epoch 20/30\n",
            "1075/1075 [==============================] - 18s 17ms/step - loss: 1.0159 - accuracy: 0.5734 - val_loss: 1.0478 - val_accuracy: 0.5641\n",
            "Epoch 21/30\n",
            "1075/1075 [==============================] - 16s 15ms/step - loss: 1.0153 - accuracy: 0.5750 - val_loss: 1.0444 - val_accuracy: 0.5631\n",
            "Epoch 22/30\n",
            "1075/1075 [==============================] - 17s 16ms/step - loss: 1.0147 - accuracy: 0.5747 - val_loss: 1.0467 - val_accuracy: 0.5621\n",
            "Epoch 23/30\n",
            "1075/1075 [==============================] - 14s 13ms/step - loss: 1.0131 - accuracy: 0.5765 - val_loss: 1.0455 - val_accuracy: 0.5521\n",
            "Epoch 24/30\n",
            "1075/1075 [==============================] - 16s 15ms/step - loss: 1.0133 - accuracy: 0.5754 - val_loss: 1.0178 - val_accuracy: 0.5733\n",
            "Epoch 25/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0129 - accuracy: 0.5757 - val_loss: 1.0206 - val_accuracy: 0.5701\n",
            "Epoch 26/30\n",
            "1075/1075 [==============================] - 20s 19ms/step - loss: 1.0122 - accuracy: 0.5767 - val_loss: 1.0805 - val_accuracy: 0.5478\n",
            "Epoch 27/30\n",
            "1075/1075 [==============================] - 19s 18ms/step - loss: 1.0103 - accuracy: 0.5769 - val_loss: 1.0219 - val_accuracy: 0.5770\n",
            "Epoch 28/30\n",
            "1075/1075 [==============================] - 20s 19ms/step - loss: 1.0105 - accuracy: 0.5762 - val_loss: 1.0349 - val_accuracy: 0.5693\n",
            "Epoch 29/30\n",
            "1075/1075 [==============================] - 17s 15ms/step - loss: 1.0101 - accuracy: 0.5765 - val_loss: 1.0278 - val_accuracy: 0.5669\n",
            "Epoch 30/30\n",
            "1075/1075 [==============================] - 14s 13ms/step - loss: 1.0097 - accuracy: 0.5772 - val_loss: 1.0417 - val_accuracy: 0.5607\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     4     23     31 ... 171876 171880 171881]\n",
            "Epoch 1/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0109 - accuracy: 0.5768 - val_loss: 1.0350 - val_accuracy: 0.5692\n",
            "Epoch 2/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0100 - accuracy: 0.5777 - val_loss: 1.0294 - val_accuracy: 0.5707\n",
            "Epoch 3/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0101 - accuracy: 0.5774 - val_loss: 1.0210 - val_accuracy: 0.5712\n",
            "Epoch 4/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0085 - accuracy: 0.5771 - val_loss: 1.0402 - val_accuracy: 0.5672\n",
            "Epoch 5/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0080 - accuracy: 0.5772 - val_loss: 1.0477 - val_accuracy: 0.5483\n",
            "Epoch 6/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0072 - accuracy: 0.5780 - val_loss: 1.0155 - val_accuracy: 0.5778\n",
            "Epoch 7/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0074 - accuracy: 0.5783 - val_loss: 1.0148 - val_accuracy: 0.5750\n",
            "Epoch 8/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0071 - accuracy: 0.5784 - val_loss: 1.0367 - val_accuracy: 0.5698\n",
            "Epoch 9/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0069 - accuracy: 0.5782 - val_loss: 1.0519 - val_accuracy: 0.5668\n",
            "Epoch 10/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0059 - accuracy: 0.5792 - val_loss: 1.0278 - val_accuracy: 0.5734\n",
            "Epoch 11/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0067 - accuracy: 0.5786 - val_loss: 1.0407 - val_accuracy: 0.5645\n",
            "Epoch 12/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0051 - accuracy: 0.5796 - val_loss: 1.0162 - val_accuracy: 0.5755\n",
            "Epoch 13/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0055 - accuracy: 0.5784 - val_loss: 1.0077 - val_accuracy: 0.5784\n",
            "Epoch 14/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0049 - accuracy: 0.5781 - val_loss: 1.0221 - val_accuracy: 0.5676\n",
            "Epoch 15/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0036 - accuracy: 0.5792 - val_loss: 1.0535 - val_accuracy: 0.5547\n",
            "Epoch 16/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0042 - accuracy: 0.5793 - val_loss: 1.0164 - val_accuracy: 0.5798\n",
            "Epoch 17/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0035 - accuracy: 0.5792 - val_loss: 1.0205 - val_accuracy: 0.5725\n",
            "Epoch 18/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0033 - accuracy: 0.5799 - val_loss: 1.0384 - val_accuracy: 0.5677\n",
            "Epoch 19/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0038 - accuracy: 0.5799 - val_loss: 1.0310 - val_accuracy: 0.5719\n",
            "Epoch 20/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0035 - accuracy: 0.5800 - val_loss: 1.0692 - val_accuracy: 0.5570\n",
            "Epoch 21/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0035 - accuracy: 0.5803 - val_loss: 1.0280 - val_accuracy: 0.5693\n",
            "Epoch 22/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0021 - accuracy: 0.5810 - val_loss: 1.0150 - val_accuracy: 0.5748\n",
            "Epoch 23/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0019 - accuracy: 0.5800 - val_loss: 1.0578 - val_accuracy: 0.5458\n",
            "Epoch 24/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0015 - accuracy: 0.5806 - val_loss: 1.0176 - val_accuracy: 0.5743\n",
            "Epoch 25/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0023 - accuracy: 0.5815 - val_loss: 1.0109 - val_accuracy: 0.5771\n",
            "Epoch 26/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0011 - accuracy: 0.5804 - val_loss: 1.0021 - val_accuracy: 0.5791\n",
            "Epoch 27/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0017 - accuracy: 0.5805 - val_loss: 1.0397 - val_accuracy: 0.5602\n",
            "Epoch 28/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0012 - accuracy: 0.5799 - val_loss: 1.0229 - val_accuracy: 0.5738\n",
            "Epoch 29/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9996 - accuracy: 0.5812 - val_loss: 1.0141 - val_accuracy: 0.5762\n",
            "Epoch 30/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0017 - accuracy: 0.5807 - val_loss: 1.0107 - val_accuracy: 0.5742\n",
            "TRAIN: [     0      1      2 ... 171881 171882 171884] TEST: [     3      8     14 ... 171883 171885 171886]\n",
            "Epoch 1/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0029 - accuracy: 0.5806 - val_loss: 1.0338 - val_accuracy: 0.5584\n",
            "Epoch 2/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0027 - accuracy: 0.5798 - val_loss: 1.0528 - val_accuracy: 0.5635\n",
            "Epoch 3/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0008 - accuracy: 0.5812 - val_loss: 1.0272 - val_accuracy: 0.5718\n",
            "Epoch 4/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0019 - accuracy: 0.5797 - val_loss: 1.0735 - val_accuracy: 0.5510\n",
            "Epoch 5/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0013 - accuracy: 0.5811 - val_loss: 1.0175 - val_accuracy: 0.5713\n",
            "Epoch 6/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0003 - accuracy: 0.5818 - val_loss: 1.0638 - val_accuracy: 0.5483\n",
            "Epoch 7/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 1.0000 - accuracy: 0.5809 - val_loss: 1.0110 - val_accuracy: 0.5762\n",
            "Epoch 8/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0019 - accuracy: 0.5806 - val_loss: 1.0216 - val_accuracy: 0.5716\n",
            "Epoch 9/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 1.0006 - accuracy: 0.5817 - val_loss: 1.0282 - val_accuracy: 0.5674\n",
            "Epoch 10/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9984 - accuracy: 0.5822 - val_loss: 1.0158 - val_accuracy: 0.5713\n",
            "Epoch 11/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 1.0002 - accuracy: 0.5815 - val_loss: 1.0375 - val_accuracy: 0.5633\n",
            "Epoch 12/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9993 - accuracy: 0.5815 - val_loss: 1.0175 - val_accuracy: 0.5752\n",
            "Epoch 13/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9990 - accuracy: 0.5825 - val_loss: 1.0187 - val_accuracy: 0.5743\n",
            "Epoch 14/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9976 - accuracy: 0.5822 - val_loss: 1.0523 - val_accuracy: 0.5575\n",
            "Epoch 15/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9985 - accuracy: 0.5821 - val_loss: 1.0019 - val_accuracy: 0.5797\n",
            "Epoch 16/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9991 - accuracy: 0.5817 - val_loss: 1.0749 - val_accuracy: 0.5576\n",
            "Epoch 17/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 0.9988 - accuracy: 0.5817 - val_loss: 1.0965 - val_accuracy: 0.5187\n",
            "Epoch 18/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9984 - accuracy: 0.5818 - val_loss: 1.0533 - val_accuracy: 0.5672\n",
            "Epoch 19/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9982 - accuracy: 0.5818 - val_loss: 1.0144 - val_accuracy: 0.5797\n",
            "Epoch 20/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9982 - accuracy: 0.5816 - val_loss: 1.0262 - val_accuracy: 0.5721\n",
            "Epoch 21/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9980 - accuracy: 0.5812 - val_loss: 1.0383 - val_accuracy: 0.5642\n",
            "Epoch 22/30\n",
            "1075/1075 [==============================] - 12s 11ms/step - loss: 0.9974 - accuracy: 0.5820 - val_loss: 1.0051 - val_accuracy: 0.5782\n",
            "Epoch 23/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9963 - accuracy: 0.5834 - val_loss: 1.0137 - val_accuracy: 0.5755\n",
            "Epoch 24/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9975 - accuracy: 0.5811 - val_loss: 1.0211 - val_accuracy: 0.5709\n",
            "Epoch 25/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9969 - accuracy: 0.5825 - val_loss: 1.0150 - val_accuracy: 0.5724\n",
            "Epoch 26/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9972 - accuracy: 0.5823 - val_loss: 1.0235 - val_accuracy: 0.5750\n",
            "Epoch 27/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9963 - accuracy: 0.5817 - val_loss: 1.0349 - val_accuracy: 0.5676\n",
            "Epoch 28/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9956 - accuracy: 0.5826 - val_loss: 1.0187 - val_accuracy: 0.5725\n",
            "Epoch 29/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9965 - accuracy: 0.5822 - val_loss: 1.0128 - val_accuracy: 0.5765\n",
            "Epoch 30/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9961 - accuracy: 0.5823 - val_loss: 1.0107 - val_accuracy: 0.5745\n",
            "TRAIN: [     0      3      4 ... 171883 171885 171886] TEST: [     1      2      6 ... 171864 171865 171884]\n",
            "Epoch 1/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9973 - accuracy: 0.5818 - val_loss: 1.0141 - val_accuracy: 0.5757\n",
            "Epoch 2/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9963 - accuracy: 0.5826 - val_loss: 1.0067 - val_accuracy: 0.5790\n",
            "Epoch 3/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9953 - accuracy: 0.5826 - val_loss: 1.0239 - val_accuracy: 0.5731\n",
            "Epoch 4/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9964 - accuracy: 0.5824 - val_loss: 1.0197 - val_accuracy: 0.5715\n",
            "Epoch 5/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9965 - accuracy: 0.5821 - val_loss: 1.0160 - val_accuracy: 0.5757\n",
            "Epoch 6/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9946 - accuracy: 0.5829 - val_loss: 1.0229 - val_accuracy: 0.5704\n",
            "Epoch 7/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9960 - accuracy: 0.5824 - val_loss: 1.0371 - val_accuracy: 0.5643\n",
            "Epoch 8/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9964 - accuracy: 0.5820 - val_loss: 1.0358 - val_accuracy: 0.5740\n",
            "Epoch 9/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9952 - accuracy: 0.5825 - val_loss: 1.0129 - val_accuracy: 0.5751\n",
            "Epoch 10/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9948 - accuracy: 0.5842 - val_loss: 1.0415 - val_accuracy: 0.5626\n",
            "Epoch 11/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9935 - accuracy: 0.5832 - val_loss: 1.0253 - val_accuracy: 0.5662\n",
            "Epoch 12/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9938 - accuracy: 0.5832 - val_loss: 1.0191 - val_accuracy: 0.5748\n",
            "Epoch 13/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9946 - accuracy: 0.5828 - val_loss: 1.0001 - val_accuracy: 0.5805\n",
            "Epoch 14/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9946 - accuracy: 0.5830 - val_loss: 1.0247 - val_accuracy: 0.5706\n",
            "Epoch 15/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9947 - accuracy: 0.5845 - val_loss: 1.0431 - val_accuracy: 0.5684\n",
            "Epoch 16/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9943 - accuracy: 0.5820 - val_loss: 1.0539 - val_accuracy: 0.5578\n",
            "Epoch 17/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9933 - accuracy: 0.5832 - val_loss: 1.0200 - val_accuracy: 0.5724\n",
            "Epoch 18/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9932 - accuracy: 0.5833 - val_loss: 1.0032 - val_accuracy: 0.5805\n",
            "Epoch 19/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9928 - accuracy: 0.5841 - val_loss: 1.0213 - val_accuracy: 0.5726\n",
            "Epoch 20/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9937 - accuracy: 0.5837 - val_loss: 1.0063 - val_accuracy: 0.5768\n",
            "Epoch 21/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9928 - accuracy: 0.5836 - val_loss: 1.0295 - val_accuracy: 0.5749\n",
            "Epoch 22/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9922 - accuracy: 0.5832 - val_loss: 1.0288 - val_accuracy: 0.5671\n",
            "Epoch 23/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9929 - accuracy: 0.5834 - val_loss: 1.0497 - val_accuracy: 0.5564\n",
            "Epoch 24/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9929 - accuracy: 0.5836 - val_loss: 1.0347 - val_accuracy: 0.5730\n",
            "Epoch 25/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9916 - accuracy: 0.5844 - val_loss: 1.0155 - val_accuracy: 0.5737\n",
            "Epoch 26/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9924 - accuracy: 0.5842 - val_loss: 1.0756 - val_accuracy: 0.5492\n",
            "Epoch 27/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9921 - accuracy: 0.5843 - val_loss: 1.0379 - val_accuracy: 0.5676\n",
            "Epoch 28/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9919 - accuracy: 0.5842 - val_loss: 1.0184 - val_accuracy: 0.5726\n",
            "Epoch 29/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9925 - accuracy: 0.5836 - val_loss: 1.0166 - val_accuracy: 0.5776\n",
            "Epoch 30/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9919 - accuracy: 0.5836 - val_loss: 1.0257 - val_accuracy: 0.5648\n",
            "TRAIN: [     0      1      2 ... 171884 171885 171886] TEST: [     5     10     15 ... 171868 171877 171882]\n",
            "Epoch 1/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9961 - accuracy: 0.5817 - val_loss: 0.9980 - val_accuracy: 0.5865\n",
            "Epoch 2/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9966 - accuracy: 0.5814 - val_loss: 0.9818 - val_accuracy: 0.5910\n",
            "Epoch 3/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9949 - accuracy: 0.5824 - val_loss: 1.0462 - val_accuracy: 0.5634\n",
            "Epoch 4/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9953 - accuracy: 0.5823 - val_loss: 1.0190 - val_accuracy: 0.5733\n",
            "Epoch 5/30\n",
            "1075/1075 [==============================] - 12s 12ms/step - loss: 0.9943 - accuracy: 0.5832 - val_loss: 1.0086 - val_accuracy: 0.5817\n",
            "Epoch 6/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9936 - accuracy: 0.5822 - val_loss: 1.0372 - val_accuracy: 0.5818\n",
            "Epoch 7/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9941 - accuracy: 0.5830 - val_loss: 1.0131 - val_accuracy: 0.5771\n",
            "Epoch 8/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9951 - accuracy: 0.5837 - val_loss: 1.0118 - val_accuracy: 0.5779\n",
            "Epoch 9/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9941 - accuracy: 0.5829 - val_loss: 0.9894 - val_accuracy: 0.5859\n",
            "Epoch 10/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9939 - accuracy: 0.5834 - val_loss: 0.9969 - val_accuracy: 0.5843\n",
            "Epoch 11/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9941 - accuracy: 0.5836 - val_loss: 1.0169 - val_accuracy: 0.5801\n",
            "Epoch 12/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9948 - accuracy: 0.5838 - val_loss: 1.0185 - val_accuracy: 0.5715\n",
            "Epoch 13/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9939 - accuracy: 0.5834 - val_loss: 1.0137 - val_accuracy: 0.5804\n",
            "Epoch 14/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9956 - accuracy: 0.5827 - val_loss: 1.0158 - val_accuracy: 0.5767\n",
            "Epoch 15/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9952 - accuracy: 0.5830 - val_loss: 1.0521 - val_accuracy: 0.5627\n",
            "Epoch 16/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9952 - accuracy: 0.5824 - val_loss: 1.0078 - val_accuracy: 0.5780\n",
            "Epoch 17/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9930 - accuracy: 0.5838 - val_loss: 1.0076 - val_accuracy: 0.5761\n",
            "Epoch 18/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9948 - accuracy: 0.5832 - val_loss: 1.0087 - val_accuracy: 0.5798\n",
            "Epoch 19/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9925 - accuracy: 0.5853 - val_loss: 1.0780 - val_accuracy: 0.5544\n",
            "Epoch 20/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9936 - accuracy: 0.5831 - val_loss: 1.0323 - val_accuracy: 0.5706\n",
            "Epoch 21/30\n",
            "1075/1075 [==============================] - 14s 13ms/step - loss: 0.9929 - accuracy: 0.5849 - val_loss: 1.0317 - val_accuracy: 0.5646\n",
            "Epoch 22/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9947 - accuracy: 0.5818 - val_loss: 1.0342 - val_accuracy: 0.5679\n",
            "Epoch 23/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9926 - accuracy: 0.5828 - val_loss: 1.0375 - val_accuracy: 0.5660\n",
            "Epoch 24/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9917 - accuracy: 0.5845 - val_loss: 1.0004 - val_accuracy: 0.5823\n",
            "Epoch 25/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9913 - accuracy: 0.5850 - val_loss: 1.0297 - val_accuracy: 0.5676\n",
            "Epoch 26/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9927 - accuracy: 0.5829 - val_loss: 1.0084 - val_accuracy: 0.5781\n",
            "Epoch 27/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9923 - accuracy: 0.5836 - val_loss: 1.0103 - val_accuracy: 0.5779\n",
            "Epoch 28/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9917 - accuracy: 0.5842 - val_loss: 0.9969 - val_accuracy: 0.5828\n",
            "Epoch 29/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9913 - accuracy: 0.5846 - val_loss: 1.0167 - val_accuracy: 0.5744\n",
            "Epoch 30/30\n",
            "1075/1075 [==============================] - 13s 12ms/step - loss: 0.9908 - accuracy: 0.5845 - val_loss: 1.0540 - val_accuracy: 0.5690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpWABC2ikRXu",
        "outputId": "5263b1bf-4f8a-4907-8475-9a3ee5501b9f"
      },
      "source": [
        "Mymodel.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 128)               896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 235,268\n",
            "Trainable params: 233,476\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKRntP1n0Idd"
      },
      "source": [
        "testday2 = [[31.566667, 20.633333, 80.000000, 3.555555, 9, 4]]\n",
        "Mymodel.predict(testday2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz4pyDUuDZTc"
      },
      "source": [
        "check = data_train.loc[data_train['Month'] == 9]\n",
        "check = check[check['State']=='AM']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBFX0fcZY3ec"
      },
      "source": [
        "history.to_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbVrkQ6U4UrP"
      },
      "source": [
        "data.to_csv('/content/drive/Shareddrives/BNCS411_Final_Project/weather_with_fires_scales.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}